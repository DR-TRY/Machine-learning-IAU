{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4a2ce5",
   "metadata": {},
   "source": [
    "# Assignment Solution: Data Quality Assessment & Preprocessing (Telco Customer Churn)\n",
    "\n",
    "This notebook solves the assignment tasks using **Dataset.xlsx**.\n",
    "\n",
    "## Tasks\n",
    "1. Identify data quality issues in the dataset  \n",
    "2. Apply one missing value strategy and explain why  \n",
    "3. Detect and handle outliers using IQR  \n",
    "4. Normalize numerical features using both Min-Max and Z-score  \n",
    "5. Apply PCA and interpret explained variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b431cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c7b58",
   "metadata": {},
   "source": [
    "## 1) Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(\"Dataset.xlsx\")\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43fadb6",
   "metadata": {},
   "source": [
    "## 2) Task 1 — Identify Data Quality Issues\n",
    "\n",
    "We will check:\n",
    "- data types\n",
    "- missing values\n",
    "- duplicate rows / duplicate IDs\n",
    "- hidden missing values stored as blank strings (especially in `TotalCharges`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic quality checks\n",
    "print(\"Data types:\")\n",
    "display(df_raw.dtypes)\n",
    "\n",
    "print(\"\\nDuplicate rows:\", df_raw.duplicated().sum())\n",
    "print(\"Duplicate customerID:\", df_raw[\"customerID\"].duplicated().sum())\n",
    "\n",
    "print(\"\\nMissing values (before conversion):\")\n",
    "display(df_raw.isna().sum().sort_values(ascending=False).to_frame(\"missing_count\").query(\"missing_count > 0\"))\n",
    "\n",
    "# Check blank strings in object columns\n",
    "blank_summary = {}\n",
    "for col in df_raw.select_dtypes(include=\"object\").columns:\n",
    "    blank_count = df_raw[col].astype(str).str.strip().eq(\"\").sum()\n",
    "    if blank_count > 0:\n",
    "        blank_summary[col] = int(blank_count)\n",
    "\n",
    "print(\"\\nBlank-string values in object columns:\")\n",
    "blank_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c53619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric (blank strings -> NaN)\n",
    "df = df_raw.copy()\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Missing values after converting TotalCharges:\")\n",
    "display(df.isna().sum().sort_values(ascending=False).to_frame(\"missing_count\").query(\"missing_count > 0\"))\n",
    "\n",
    "# Inspect rows with missing TotalCharges\n",
    "df[df[\"TotalCharges\"].isna()][[\"customerID\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870ad0d",
   "metadata": {},
   "source": [
    "### Task 1 Findings (Summary)\n",
    "- Dataset has **7043 rows** and **21 columns**\n",
    "- Duplicate rows: **0**\n",
    "- Duplicate `customerID`: **0**\n",
    "- Main issue: `TotalCharges` is read as **object** due to blank strings\n",
    "- After conversion, `TotalCharges` contains **11 missing values (NaN)**\n",
    "\n",
    "> These are hidden missing values and must be handled before preprocessing/modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4bede",
   "metadata": {},
   "source": [
    "## 3) Task 2 — Missing Value Strategy (and Why)\n",
    "\n",
    "### Chosen strategy: **Domain-aware imputation**\n",
    "For this Telco dataset, missing values in `TotalCharges` happen for customers with `tenure = 0` (new customers).\n",
    "That means their total accumulated charges should logically be **0**.\n",
    "\n",
    "**Why this is better than mean/median here:**\n",
    "- It preserves business meaning\n",
    "- It avoids injecting artificial spending values into new customers\n",
    "- It is more accurate than generic statistical imputation for this specific case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Fill missing TotalCharges with 0 only when tenure == 0 (domain-aware)\n",
    "mask = df_clean[\"TotalCharges\"].isna() & (df_clean[\"tenure\"] == 0)\n",
    "df_clean.loc[mask, \"TotalCharges\"] = 0.0\n",
    "\n",
    "# Defensive fallback (should not be needed in this dataset)\n",
    "if df_clean[\"TotalCharges\"].isna().sum() > 0:\n",
    "    df_clean[\"TotalCharges\"] = df_clean[\"TotalCharges\"].fillna(df_clean[\"TotalCharges\"].median())\n",
    "\n",
    "print(\"Remaining missing values in TotalCharges:\", df_clean[\"TotalCharges\"].isna().sum())\n",
    "df_clean[[\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f35d0",
   "metadata": {},
   "source": [
    "Filled rows using domain-aware rule (`tenure == 0` → `TotalCharges = 0`): **11**  \n",
    "Remaining missing values in `TotalCharges`: **0**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa0ba8",
   "metadata": {},
   "source": [
    "## 4) Task 3 — Detect and Handle Outliers Using IQR\n",
    "\n",
    "We will apply the **IQR method** on the main continuous numerical features:\n",
    "- `tenure`\n",
    "- `MonthlyCharges`\n",
    "- `TotalCharges`\n",
    "\n",
    "### IQR rule\n",
    "A value is considered an outlier if:\n",
    "- `< Q1 - 1.5 × IQR` or\n",
    "- `> Q3 + 1.5 × IQR`\n",
    "\n",
    "### Handling approach\n",
    "We use **IQR capping (winsorization)**:\n",
    "- values below lower bound are clipped to lower bound\n",
    "- values above upper bound are clipped to upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d420cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "df_iqr = df_clean.copy()\n",
    "\n",
    "iqr_summary = []\n",
    "\n",
    "for col in num_cols:\n",
    "    q1 = df_iqr[col].quantile(0.25)\n",
    "    q3 = df_iqr[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "\n",
    "    outlier_mask = (df_iqr[col] < lower) | (df_iqr[col] > upper)\n",
    "    outlier_count = int(outlier_mask.sum())\n",
    "\n",
    "    before = df_iqr[col].copy()\n",
    "    df_iqr[col] = df_iqr[col].clip(lower, upper)\n",
    "    capped_count = int((before != df_iqr[col]).sum())\n",
    "\n",
    "    iqr_summary.append({\n",
    "        \"feature\": col,\n",
    "        \"Q1\": q1,\n",
    "        \"Q3\": q3,\n",
    "        \"IQR\": iqr,\n",
    "        \"lower_bound\": lower,\n",
    "        \"upper_bound\": upper,\n",
    "        \"outlier_count\": outlier_count,\n",
    "        \"capped_count\": capped_count\n",
    "    })\n",
    "\n",
    "iqr_summary_df = pd.DataFrame(iqr_summary)\n",
    "iqr_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots after handling (for visual check)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, col in zip(axes, [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]):\n",
    "    sns.boxplot(x=df_iqr[col], ax=ax)\n",
    "    ax.set_title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad4014",
   "metadata": {},
   "source": [
    "### Task 3 Result\n",
    "- Total outliers detected across selected features (using standard **1.5×IQR**): **0**\n",
    "- If `capped_count = 0`, it means the feature had **no outliers under the IQR rule**, so the data remains unchanged for that feature.\n",
    "\n",
    "This is a valid outcome and should be reported clearly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cda831",
   "metadata": {},
   "source": [
    "## 5) Task 4 — Normalize Numerical Features (Min-Max and Z-score)\n",
    "\n",
    "We normalize the same continuous numerical features:\n",
    "- `tenure`\n",
    "- `MonthlyCharges`\n",
    "- `TotalCharges`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "\n",
    "# Min-Max normalization\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_minmax = df_iqr.copy()\n",
    "df_minmax[[f\"{c}_MinMax\" for c in num_cols]] = minmax_scaler.fit_transform(df_iqr[num_cols])\n",
    "\n",
    "# Z-score normalization\n",
    "zscore_scaler = StandardScaler()\n",
    "df_zscore = df_iqr.copy()\n",
    "df_zscore[[f\"{c}_Z\" for c in num_cols]] = zscore_scaler.fit_transform(df_iqr[num_cols])\n",
    "\n",
    "print(\"Min-Max summary (should be between 0 and 1):\")\n",
    "display(df_minmax[[f\"{c}_MinMax\" for c in num_cols]].agg([\"min\", \"max\"]))\n",
    "\n",
    "print(\"Z-score summary (mean ≈ 0, std ≈ 1):\")\n",
    "display(df_zscore[[f\"{c}_Z\" for c in num_cols]].agg([\"mean\", \"std\"]))\n",
    "\n",
    "df_minmax[[f\"{c}_MinMax\" for c in num_cols]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97b27f",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- **Min-Max** scales each feature into the range **[0, 1]**\n",
    "- **Z-score** standardization centers data around **0** with standard deviation near **1**\n",
    "- PCA is typically applied after **Z-score standardization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211d1cc",
   "metadata": {},
   "source": [
    "## 6) Task 5 — PCA and Explained Variance\n",
    "\n",
    "We apply PCA on the **standardized numerical features** (`tenure`, `MonthlyCharges`, `TotalCharges`) and interpret how much variance each principal component explains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7976bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized matrix for PCA\n",
    "X_std = zscore_scaler.fit_transform(df_iqr[num_cols])\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_std)\n",
    "\n",
    "explained_variance_df = pd.DataFrame({\n",
    "    \"PC\": [f\"PC{i+1}\" for i in range(X_std.shape[1])],\n",
    "    \"explained_variance_ratio\": pca.explained_variance_ratio_,\n",
    "    \"cumulative_explained_variance\": np.cumsum(pca.explained_variance_ratio_)\n",
    "})\n",
    "\n",
    "loadings_df = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    index=num_cols,\n",
    "    columns=explained_variance_df[\"PC\"]\n",
    ")\n",
    "\n",
    "display(explained_variance_df)\n",
    "display(loadings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87342b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree + cumulative explained variance\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(explained_variance_df[\"PC\"], explained_variance_df[\"explained_variance_ratio\"], marker=\"o\", label=\"Explained Variance Ratio\")\n",
    "plt.plot(explained_variance_df[\"PC\"], explained_variance_df[\"cumulative_explained_variance\"], marker=\"s\", label=\"Cumulative Explained Variance\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.ylabel(\"Variance Ratio\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# PCA scatter (PC1 vs PC2)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.4, s=12)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA Projection (PC1 vs PC2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256b413",
   "metadata": {},
   "source": [
    "### PCA Interpretation (This Dataset)\n",
    "- **PC1 explains 72.69%** of the variance.\n",
    "- **PC1 + PC2 explain 98.01%** of the variance.\n",
    "- This means the first **2 components** preserve almost all information in the 3 standardized numerical features.\n",
    "- So dimensionality can be reduced from **3 features → 2 principal components** with minimal information loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38e3eb",
   "metadata": {},
   "source": [
    "## 7) Export Files for GitHub / Submission\n",
    "\n",
    "The following exports are created:\n",
    "- cleaned dataset (after missing value handling)\n",
    "- IQR summary\n",
    "- dataset after outlier handling\n",
    "- Min-Max normalized version\n",
    "- Z-score normalized version\n",
    "- PCA explained variance and loadings\n",
    "- PCA component scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export output files\n",
    "df_clean.to_csv(\"telco_preprocessing_results/01_telco_cleaned_missing_handled.csv\", index=False)\n",
    "iqr_summary_df.to_csv(\"telco_preprocessing_results/02_iqr_outlier_summary.csv\", index=False)\n",
    "df_iqr.to_csv(\"telco_preprocessing_results/03_telco_after_iqr_handling.csv\", index=False)\n",
    "df_minmax.to_csv(\"telco_preprocessing_results/04_telco_minmax_normalized.csv\", index=False)\n",
    "df_zscore.to_csv(\"telco_preprocessing_results/05_telco_zscore_normalized.csv\", index=False)\n",
    "explained_variance_df.to_csv(\"telco_preprocessing_results/06_pca_explained_variance.csv\", index=False)\n",
    "loadings_df.to_csv(\"telco_preprocessing_results/07_pca_loadings.csv\")\n",
    "pd.DataFrame(X_pca, columns=[f\"PC{i+1}\" for i in range(X_pca.shape[1])]).to_csv(\"telco_preprocessing_results/08_pca_components_dataset.csv\", index=False)\n",
    "\n",
    "print(\"All output files saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
